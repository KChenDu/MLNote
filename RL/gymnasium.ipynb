{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be using [gymnasium](https://github.com/Farama-Foundation/Gymnasium), a great toolkit for developing and comparing Reinforcement Learning algorithms. It provides many environments for your learning agents to interact with.\n",
    "\n",
    "The CartPole (version 1) is a very simple environment composed of a cart that can move left or right, and pole placed vertically on top of it. The agent must move the cart left or right to keep the pole upright.\n",
    "\n",
    "**Tip**: `gym.envs.registry` is a dictionary containing all available environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acrobot-v1', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'BipedalWalker-v3', '...']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# extra code – shows the first few environments\n",
    "envs = gym.envs.registry\n",
    "sorted(envs.keys())[:5] + [\"...\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The registry values are environment specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvSpec(id='CartPole-v1', entry_point='gymnasium.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPole', version=1, additional_wrappers=(), vector_entry_point='gymnasium.envs.classic_control.cartpole:CartPoleVectorEnv')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows the specification for the CartPole-v1 environment\n",
    "envs[\"CartPole-v1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize the environment by calling is `reset()` method. This returns an observation, as well as a dictionary that may contain extra information. Both are environment-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0273956 , -0.00611216,  0.03585979,  0.0197368 ], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, info = env.reset(seed=42)\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the CartPole, each observation is a 1D NumPy array composed of 4 floats: they represent the cart's horizontal position, its velocity, the angle of the pole (0 = vertical), and the angular velocity.\n",
    "\n",
    "An environment can be visualized by calling its `render()` method. If you set `render_mode` to `\"rgb_array\"` when creating the environment, then this will return a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 600, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = env.render()\n",
    "img.shape  # height, width, channels (3 = Red, Green, Blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extra code – creates a little function to render and plot an environment\n",
    "\n",
    "def plot_environment(env, figsize=(5, 4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    return img\n",
    "\n",
    "plot_environment(env)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how to interact with an environment. Your agent will need to select an action from an \"action space\" (the set of possible actions). Let's see what this environment's action space looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, just two possible actions: accelerate towards the left (0) or towards the right (1).\n",
    "\n",
    "Since the pole is leaning toward the right (`obs[2] > 0`), let's accelerate the cart toward the right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02727336,  0.18847767,  0.03625453, -0.26141977], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = 1  # accelerate right\n",
    "obs, reward, done, truncated, info = env.step(action)\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the cart is now moving toward the right (`obs[1] > 0`). The pole is still tilted toward the right (`obs[2] > 0`), but its angular velocity is now negative (`obs[3] < 0`), so it will likely be tilted toward the left after the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extra code – displays the environment\n",
    "plot_environment(env)\n",
    "save_fig(\"cart_pole_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's doing what we're telling it to do!\n",
    "\n",
    "The environment also tells the agent how much reward it got during the last step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the game is over, the environment returns `done=True`. In this case, it's not over yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some environment wrappers may want to interrupt the environment early. For example, when a time limit is reached or when an object goes out of bounds. In this case, `truncated` will be set to `True`. In this case, it's not truncated yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `info` is an environment-specific dictionary that can provide some extra information that you may find useful for debugging or for training. For example, in some games it may indicate how many lives the agent has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence of steps between the moment the environment is reset until it is done or truncated is called an \"episode\". At the end of an episode (i.e., when `step()` returns `done=True` or `truncated=True`), you should reset the environment before you continue to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if done or truncated:\n",
    "    obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[返回](readme.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
