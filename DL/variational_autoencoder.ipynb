{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变分自编码器\n",
    "为了从模型生成样本，VAE首先从编码分布$p_\\mathrm{model}(z)$中采样$z$。然后使样本通过可微生成器网络$g(z)$。最后，从分布$p_\\mathrm{model}(x; g(z)) = p_\\mathrm{model}(x | z)$中采样$x$\n",
    "\n",
    "变分自编码器背后的关键思想是，它们可以通过最大化与数据点$x$相关联的变分下界$\\mathcal L(q)$来训练：$\\mathcal L(q) = \\mathbb E_{z \\sim q(z | x)}\\log p_\\mathrm{model}(z, x) + \\mathcal H(q(z | x)) = \\mathbb E_{z \\sim q(z | x)}\\log p_\\mathrm{model}(x | z) - D_{\\mathrm{KL}}(q(z | x) \\| p_\\mathrm{model}(z)) \\leq \\log p_\\mathrm{model}(x)$\n",
    "\n",
    "VAE框架已不仅仅扩展到传统的变分下界，还有重要**加权自编码器**：$\\mathcal L_k(x, q) = \\mathbb E_{z^{(1)}, \\dots, z^{(k)} \\sim q(z | x)}[\\log\\frac1k\\sum_{i = 1}^k\\frac{p_\\mathrm{model}(x, z^{(i)})}{q(z^{(i)} | x)}]$\n",
    "\n",
    "变分自编码器的一个非常好的特性是，同时训练参数编码器与生成器网络的组合迫使模型学习一个编码器可以捕获的可预测的坐标系。这使得它成为一个优秀的流形学习算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return tf.random.normal(tf.shape(log_var)) * tf.exp(log_var / 2) + mean\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "\n",
    "# extra code – loads, scales, and splits the fashion MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "\n",
    "def plot_reconstructions(model, images=X_valid, n_images=5):\n",
    "    reconstructions = np.clip(model.predict(images[:n_images]), 0, 1)\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plt.imshow(images[image_index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plt.imshow(reconstructions[image_index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "codings_size = 10\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[codings_size])\n",
    "x = tf.keras.layers.Dense(100, activation=\"relu\")(decoder_inputs)\n",
    "x = tf.keras.layers.Dense(150, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(28 * 28)(x)\n",
    "outputs = tf.keras.layers.Reshape([28, 28])(x)\n",
    "variational_decoder = tf.keras.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
    "\n",
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "\n",
    "codings_size = 10\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=[28, 28])\n",
    "Z = tf.keras.layers.Flatten()(inputs)\n",
    "Z = tf.keras.layers.Dense(150, activation=\"relu\")(Z)\n",
    "Z = tf.keras.layers.Dense(100, activation=\"relu\")(Z)\n",
    "codings_mean = tf.keras.layers.Dense(codings_size)(Z)  # μ\n",
    "codings_log_var = tf.keras.layers.Dense(codings_size)(Z)  # γ\n",
    "codings = Sampling()([codings_mean, codings_log_var])\n",
    "variational_encoder = tf.keras.Model(\n",
    "    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
    "_, _, codings = variational_encoder(inputs)\n",
    "reconstructions = variational_decoder(codings)\n",
    "variational_ae = tf.keras.Model(inputs=[inputs], outputs=[reconstructions])\n",
    "latent_loss = -0.5 * tf.reduce_sum(\n",
    "    1 + codings_log_var - tf.exp(codings_log_var) - tf.square(codings_mean),\n",
    "    axis=-1)\n",
    "variational_ae.add_loss(tf.reduce_mean(latent_loss) / 784.)\n",
    "variational_ae.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = variational_ae.fit(X_train, X_train, epochs=25, batch_size=128,\n",
    "                             validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstructions(variational_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Fashion Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "\n",
    "codings = tf.random.normal(shape=[3 * 7, codings_size])\n",
    "images = variational_decoder(codings).numpy()\n",
    "\n",
    "# extra code – this cells generates and saves Figure 17-12\n",
    "\n",
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = images.squeeze(axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plot_multiple_images(images, 7)\n",
    "save_fig(\"vae_generated_images_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "\n",
    "codings = np.zeros([7, codings_size])\n",
    "codings[:, 3] = np.linspace(-0.8, 0.8, 7)  # axis 3 looks best in this case\n",
    "images = variational_decoder(codings).numpy()\n",
    "\n",
    "# extra code – this cell generates and saves Figure 17–13\n",
    "plot_multiple_images(images)\n",
    "save_fig(\"semantic_interpolation_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[返回](deep_generative_model.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
